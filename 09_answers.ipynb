{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. What are the main benefits of creating a computation graph rather than directly executing the computations? What are the main drawbacks?\n",
    "\n",
    "TensorFlow can allocate nodes to multiple CPUs/GPUs/Servers and parallelly execute computations. Which can dramatically speed up complicated learning algorithms.\n",
    "\n",
    "The main drawbacks are more complicated concepts and architectures.\n",
    "\n",
    "* 2. Is the statement a_val = a.eval(session=sess) equivalent to a_val = sess.run(a) ?\n",
    "\n",
    "Yes.\n",
    "\n",
    "* 3. Is the statement a_val, b_val = a.eval(session=sess), b.eval(session=sess) equivalent to a_val, b_val = sess.run([a, b]) ?\n",
    "\n",
    "No, the first one runs in sequential but the second one runs in parallel.\n",
    "\n",
    "* 4. Can you run two graphs in the same session?\n",
    "\n",
    "No.\n",
    "\n",
    "* 5. If you create a graph g containing a variable w , then start two threads and open a session in each thread, both using the same graph g , will each session have its own copy of the variable w or will it be shared?\n",
    "\n",
    "Each session have its own copy of the variable w.\n",
    "\n",
    "* 6. When is a variable initialized? When is it destroyed?\n",
    "\n",
    "When first it's used. When session is closed it is destroyed.\n",
    "\n",
    "* 7. What is the difference between a placeholder and a variable?\n",
    "\n",
    "A placeholder takes its values via a feed_dict and never change during running time. A variable can change during running time and usually initialized when defined.\n",
    "\n",
    "* 8. What happens when you run the graph to evaluate an operation that depends on a placeholder but you don’t feed its value? What happens if the operation does not depend on the placeholder?\n",
    "\n",
    "An exception is thrown. Operation gets evaluated without anything regards to the placeholders.\n",
    "\n",
    "* 9. When you run a graph, can you feed the output value of any operation, or just the value of placeholders?\n",
    "\n",
    "Yes. To forcely *set* the output instead of evaluated it.\n",
    "\n",
    "* 10. How can you set a variable to any value you want (during the execution phase)?\n",
    "\n",
    "Using tf.assign\n",
    "\n",
    "* 11. How many times does reverse-mode autodiff need to traverse the graph in order to compute the gradients of the cost function with regards to 10 variables? What about forward-mode autodiff? And symbolic differentiation?\n",
    "\n",
    "11; n_sampels + 1; ?\n",
    "\n",
    "* 12. Implement Logistic Regression with Mini-batch Gradient Descent using Tensor‐Flow. Train it and evaluate it on the moons dataset (introduced in Chapter 5). Try adding all the bells and whistles:\n",
    "    * Define the graph within a logistic_regression() function that can be reused easily.\n",
    "    * Save checkpoints using a Saver at regular intervals during training, and save the final model at the end of training.\n",
    "    * Restore the last checkpoint upon startup if training was interrupted.\n",
    "    * Define the graph using nice scopes so the graph looks good in TensorBoard.\n",
    "    * Add summaries to visualize the learning curves in TensorBoard.\n",
    "    * Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve.\n",
    "    \n",
    "Pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

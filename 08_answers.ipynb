{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove less useful features and nosies, also speed up learning alrogithms. Main drawbacks are loss of information.\n",
    "\n",
    "2. High dimensionality create very parse instances, and make machine learning much harder to find corelationships.\n",
    "\n",
    "3. No it's not 100% reverseable, because projection lose information. But reconstruction can certainly reverse and reflect the original instances.\n",
    "\n",
    "4. Yes, with non-leanear kernel PCA\n",
    "\n",
    "5. Around 150 features.\n",
    "\n",
    "6. Vanilla PCA for ?, Incremental PCA for online or very large datasets, Randomized PCA for ?, Kernel PCA for nonlinear datasets.\n",
    "\n",
    "7. Use downstream learning algorithm and validations to fine tune PCA hyperparameters.\n",
    "\n",
    "8. No.\n",
    "\n",
    "9. Pending\n",
    "\n",
    "10. Pending\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
